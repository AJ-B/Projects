{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#COMPARE DEFINITIONS FROM TEXT WORDS TO DEFINITIONS FROM DESCRIPTION WORDS\n",
    "\n",
    "\n",
    "#the standard\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#will clean the emoji descriptions using stop words\n",
    "import nltk\n",
    "#nltk.download()\n",
    "#from nltk import tag\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "StopWords = stopwords.words(\"english\")\n",
    "\n",
    "#will be doing some punctuation cleaning\n",
    "import string\n",
    "\n",
    "#will be using synonyms of words in the emoji descriptions\n",
    "from PyDictionary import PyDictionary\n",
    "dictionary=PyDictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Used word2vec to create VSM\n",
    "from gensim.models import word2vec\n",
    "\n",
    "#load W2V VSM model\n",
    "#model = word2vec.Word2Vec.load_word2vec_format('word2vec/text8.model.bin', binary=True)\n",
    "\n",
    "googlenews = 'word2vec/GoogleNews-vectors-negative300.bin.gz'\n",
    "model = word2vec.Word2Vec.load_word2vec_format(googlenews, binary=True)\n",
    "\n",
    "#testing\n",
    "#pos = \"woman king\".lower().split(\" \")\n",
    "#print model.most_similar(positive=pos, negative=['man'], topn=5)\n",
    "\n",
    "#val = model['woman'] + model['king'] - model['man']  \n",
    "#print np.dot(val,model[\"queen\"])/( np.linalg.norm(model['queen']) * np.linalg.norm(val) )\n",
    "\n",
    "#print model.most_similar(positive=val, topn=5)\n",
    "#print model.similarity(val,'woman')\n",
    "#print np.sum(model[['woman','king']], axis=0)- model['woman'] - model['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(v1,v2):\n",
    "    x = np.dot(v1,v2)/( np.linalg.norm(v1) * np.linalg.norm(v2) )\n",
    "    return x\n",
    "\n",
    "def wdm(v1,v2):\n",
    "    x = 1./np.linalg.norm(v1-v2)\n",
    "    if np.isfinite(x):\n",
    "        return x\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842\n",
      "835\n",
      "      Description Native             Bytes                R-encoding  \\\n",
      "0  aerial tramway     üö°  \\xF0\\x9F\\x9A\\xA1  <ed><a0><bd><ed><ba><a1>   \n",
      "1        airplane      ‚úà      \\xE2\\x9C\\x88              <e2><9c><88>   \n",
      "2     alarm clock      ‚è∞      \\xE2\\x8F\\xB0              <e2><8f><b0>   \n",
      "3   alien monster     üëæ  \\xF0\\x9F\\x91\\xBE  <ed><a0><bd><ed><b1><be>   \n",
      "4       ambulance     üöë  \\xF0\\x9F\\x9A\\x91  <ed><a0><bd><ed><ba><91>   \n",
      "\n",
      "                                         Synonyms  \\\n",
      "0    aerial flying airy tramway trim away dragway   \n",
      "1                           airplane jet aircraft   \n",
      "2  alarm nervousness dismay clock alarm timepiece   \n",
      "3        alien exotic unusual monster giant devil   \n",
      "4                      ambulance transport rescue   \n",
      "\n",
      "                                            DefWords  \\\n",
      "0  existing living growing operating air characte...   \n",
      "1  aircraft fixed wing powered propellers jets bl...   \n",
      "2  fill apprehension alarm cause unpleasantly sur...   \n",
      "3  contained deriving essential nature something ...   \n",
      "4  vehicle takes people hospitals move something ...   \n",
      "\n",
      "                                             DescDef  \n",
      "0  existing living growing operating air characte...  \n",
      "1        aircraft fixed wing powered propellers jets  \n",
      "2  fill apprehension alarm cause unpleasantly sur...  \n",
      "3  contained deriving essential nature something ...  \n",
      "4                     vehicle takes people hospitals  \n"
     ]
    }
   ],
   "source": [
    "#Load emoji data\n",
    "emoji_key = pd.read_csv('emojis/emojiDict_complete.csv', sep=';')\n",
    "# print emoji_key.head(5)\n",
    "print len(emoji_key.Bytes.values)\n",
    "emoji_key = emoji_key.dropna()\n",
    "print len(emoji_key.Bytes.values)\n",
    "print emoji_key.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Description Native             Bytes                R-encoding  \\\n",
      "124     chicken     üêî  \\xF0\\x9F\\x90\\x94  <ed><a0><bd><ed><b0><94>   \n",
      "\n",
      "                     Synonyms  \\\n",
      "124  chicken poltroon dastard   \n",
      "\n",
      "                                              DefWords  \\\n",
      "124  easily frightened characterized complete cowar...   \n",
      "\n",
      "                                               DescDef  \n",
      "124  easily frightened flesh chicken used food dome...  \n"
     ]
    }
   ],
   "source": [
    "#reset index for datafram\n",
    "emoji_key = emoji_key.reset_index(drop=True)\n",
    "print emoji_key[emoji_key['Description']==\"chicken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GET SIMILARITY BASED ON AVERAGED SIMILARITY BETWEEN WORDS IN MODEL\n",
    "def compare(l1,l2):\n",
    "    x=0.\n",
    "    n=0.\n",
    "    for w1 in l1:\n",
    "        #print w1\n",
    "        for w2 in l2:\n",
    "            #print w1, w2\n",
    "            #get model similarity for every synonym\n",
    "            try:\n",
    "                x += model.similarity(w1, w2)\n",
    "                n += 1.\n",
    "            except:\n",
    "                x += 0.\n",
    "                n += 0.\n",
    "            if x==0:\n",
    "                n=1\n",
    "            #print x\n",
    "\n",
    "    return x/n\n",
    "    \n",
    "# s1 = \"Take bus school\".lower().split(\" \")\n",
    "# s2 = emoji_key.DefWords.values[0].split(\" \")\n",
    "# print compare(s1,s2)\n",
    "# s1 = \"Love cake\".lower().split(\" \")\n",
    "# s2 = emoji_key.DefWords.values[0].split(\" \")\n",
    "# print compare(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicken']\n",
      "False\n",
      "0.137762\n"
     ]
    }
   ],
   "source": [
    "#GET SIMILARITY BASED ON SIMILARITY BETWEEN WORDS VECTOR SUM LOCATIONS IN MODEL\n",
    "def compare_alt(l1,l2):\n",
    "    s1 = l1[:]\n",
    "    s2 = l2[:]\n",
    "    for w1 in l1:\n",
    "        try:\n",
    "            x = model[w1]\n",
    "        except:\n",
    "            s1.remove(w1)\n",
    "    for w2 in l2:\n",
    "        try:\n",
    "            x = model[w2]\n",
    "        except:\n",
    "            s2.remove(w2)\n",
    "    \n",
    "    if len(s1)==0 or len(s2)==0:\n",
    "        return 0.\n",
    "    \n",
    "    v1 = np.sum(model[s1], axis=0)\n",
    "    v2 = np.sum(model[s2], axis=0)\n",
    "    \n",
    "    return cos_sim(v1,v2)\n",
    "\n",
    "s1 = ['easily','caught']\n",
    "s2 = emoji_key.Description[124].split(\" \")#emoji_key.DescDef[124].split(\" \")[:3]\n",
    "print s2\n",
    "print s1==s2\n",
    "\n",
    "print compare_alt(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicken']\n",
      "False\n",
      "0.313535741344\n"
     ]
    }
   ],
   "source": [
    "#GET SIMILARITY BASED ON SIMILARITY BETWEEN 2 SENTENCES (vector average then take euclidian distance)\n",
    "def compare_alt1(l1,l2,avg):\n",
    "    s1 = l1[:]\n",
    "    s2 = l2[:]\n",
    "    for w1 in l1:\n",
    "        try:\n",
    "            x = model[w1]\n",
    "        except:\n",
    "            s1.remove(w1)\n",
    "    for w2 in l2:\n",
    "        try:\n",
    "            x = model[w2]\n",
    "        except:\n",
    "            s2.remove(w2)\n",
    "    \n",
    "    if len(s1)==0 or len(s2)==0:\n",
    "        return 0.\n",
    "\n",
    "    v1 = np.sum(model[s1], axis=0)\n",
    "    v2 = np.sum(model[s2], axis=0)\n",
    "    \n",
    "    if avg==True:\n",
    "        v1 = v1/float(len(s1))\n",
    "        v2 = v2/float(len(s2))\n",
    "        \n",
    "    #print cos_sim(v1,v2)\n",
    "    return wdm(v1,v2)\n",
    "\n",
    "s1 = ['easily','caught']\n",
    "s2 = emoji_key.Description[124].split(\" \")#emoji_key.DescDef[124].split(\" \")[:3]\n",
    "print s2\n",
    "print s1==s2\n",
    "\n",
    "print compare_alt1(s1,s2, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean the emoji descriptions for easy use later\n",
    "def Clean(text):\n",
    "    #REMOVE STOPWORDS\n",
    "    text = ' '.join([word.lower() for word in text.split() if word not in StopWords])\n",
    "    #remove punctuation\n",
    "    text = text.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run move quickly hastily break pieces striking knocking hurl thrust violently destroy break cause lose courage add enlivening altering element distinctive stylish elegance quick run footrace run top speed punctuation mark  longer two telegraphic signals used morse code act moving great haste arbitrary sign written printed something visible association convention represents something else invisible\n"
     ]
    }
   ],
   "source": [
    "print emoji_key.values[205][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usr txt: You had time to call the police\n",
      "had:\n",
      "üò• disappointed but relieved face 2.39211500238\n",
      "üíë couple with heart 2.37536911627\n",
      "üåú last quarter moon with face 2.34546671598\n",
      "time:\n",
      "üåõ first quarter moon with face 2.53346713831\n",
      "üåú last quarter moon with face 2.48977340708\n",
      "üïï clock face six oclock 2.4344607546\n",
      "call:\n",
      "‚òé black telephone 2.20662805239\n",
      "üì± mobile phone 2.19044418922\n",
      "üì¥ mobile phone off 2.15383582704\n",
      "police:\n",
      "üëÆ police officer 3.30456808557\n",
      "üöì police car 3.00805129481\n",
      "üöî oncoming police car 2.58604385977\n",
      "You\n",
      "üò•\n",
      "üåõ\n",
      "to\n",
      "‚òé\n",
      "the\n",
      "üëÆ\n",
      "\n",
      "\n",
      "Usr txt: I am going to marry her\n",
      "am:\n",
      "üåâ bridge at night 1.96661203975\n",
      "üïê clock face one oclock 1.90043389298\n",
      "üöØ do not litter symbol 1.86950219636\n",
      "going:\n",
      "üôã happy person raising one hand 2.52042287833\n",
      "üò• disappointed but relieved face 2.48821487658\n",
      "üöØ do not litter symbol 2.46780593089\n",
      "marry:\n",
      "üíí wedding 2.7084891554\n",
      "üë∞ bride with veil 1.67534462706\n",
      "üë© woman 1.58610221403\n",
      "I\n",
      "üåâ\n",
      "üôã\n",
      "to\n",
      "üíí\n",
      "her\n",
      "\n",
      "\n",
      "Usr txt: Are you taking his side against me\n",
      "Are:\n",
      "üò´ tired face 1.80067889854\n",
      "üôà see no evil monkey 1.79642966179\n",
      "üò® fearful face 1.79580424591\n",
      "taking:\n",
      "üë¨ two men holding hands 2.29230537827\n",
      "üë≠ two women holding hands 2.27246335869\n",
      "üôå person raising both hands in celebration 2.20964993644\n",
      "side:\n",
      "üîÇ clockwise rightwards and leftwards open circle arrows with circled one overlay 2.38982811669\n",
      "üîö end with leftwards arrow above 2.3623627141\n",
      "üîõ on with exclamation mark with left right arrow above 2.31087461672\n",
      "üò´\n",
      "you\n",
      "üë¨\n",
      "his\n",
      "üîÇ\n",
      "against\n",
      "me\n",
      "\n",
      "\n",
      "Usr txt: What do you mean youve lost the lottery ticket\n",
      "do:\n",
      "üöØ do not litter symbol 3.09925202825\n",
      "üôà see no evil monkey 2.67337765831\n",
      "üôâ hear no evil monkey 2.61837456349\n",
      "mean:\n",
      "üöØ do not litter symbol 2.33689942268\n",
      "üôÖ face with no good gesture 2.25868087659\n",
      "üôÜ face with ok gesture 2.24060428875\n",
      "lost:\n",
      "üçÇ fallen leaf 2.1035486455\n",
      "üò• disappointed but relieved face 2.02242031214\n",
      "üíî broken heart 2.00978212531\n",
      "lottery:\n",
      "üé´ ticket 1.81163178601\n",
      "üé¥ flower playing cards 1.69759662831\n",
      "‚òë ballot box with check 1.66625801952\n",
      "ticket:\n",
      "üé´ ticket 4.84375979931\n",
      "‚òë ballot box with check 1.9271388003\n",
      "üí≥ credit card 1.92196181291\n",
      "What\n",
      "üöØ\n",
      "you\n",
      "üöØ\n",
      "youve\n",
      "üçÇ\n",
      "the\n",
      "üé´\n",
      "üé´\n",
      "\n",
      "\n",
      "Usr txt: If you do this you will be dead to me\n",
      "do:\n",
      "üöØ do not litter symbol 3.09925202825\n",
      "üôà see no evil monkey 2.67337765831\n",
      "üôâ hear no evil monkey 2.61837456349\n",
      "will:\n",
      "üöØ do not litter symbol 2.05874313832\n",
      "üåö new moon with face 2.04532225433\n",
      "üôå person raising both hands in celebration 2.00547774005\n",
      "be:\n",
      "üôå person raising both hands in celebration 2.34833274861\n",
      "üôÖ face with no good gesture 2.32358550565\n",
      "üöØ do not litter symbol 2.31248687431\n",
      "dead:\n",
      "üé≤ game die 2.11754943951\n",
      "üòø crying cat face 2.03874379056\n",
      "üë´ man and woman holding hands 2.00847670874\n",
      "If\n",
      "you\n",
      "üöØ\n",
      "this\n",
      "you\n",
      "üöØ\n",
      "üôå\n",
      "üé≤\n",
      "to\n",
      "me\n",
      "\n",
      "\n",
      "Usr txt: What do you remember about your mother\n",
      "do:\n",
      "üöØ do not litter symbol 3.09925202825\n",
      "üôà see no evil monkey 2.67337765831\n",
      "üôâ hear no evil monkey 2.61837456349\n",
      "remember:\n",
      "üò≠ loudly crying face 2.09998605015\n",
      "üò¢ crying face 2.06966316108\n",
      "üò§ face with look of triumph 2.06372842703\n",
      "mother:\n",
      "üë© woman 2.9859837419\n",
      "üëß girl 2.88744416364\n",
      "üëµ older woman 2.76807863775\n",
      "What\n",
      "üöØ\n",
      "you\n",
      "üò≠\n",
      "about\n",
      "your\n",
      "üë©\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anael\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# sentences = [\"watching soccer Love Cake like eat chicken fingers\",\\\n",
    "#              \"take car downtown shake bake bottled water dinner morning\",\\\n",
    "#              \"Why can't the rattled galaxy shoot the raw arrogance\",\\\n",
    "#              \"Can a cupboard rage?\",\\\n",
    "#              \"at the gym lifting weights\"]\n",
    "\n",
    "sentences = [\n",
    "    \"You had time to call the police\",\\\n",
    "    \"I am going to marry her\",\\\n",
    "    \"Are you taking his side against me\",\\\n",
    "    \"What do you mean, you've lost the lottery ticket\",\\\n",
    "    \"If you do this, you will be dead to me\",\\\n",
    "    \"What do you remember about your mother?\"\n",
    "]\n",
    "\n",
    "# sentences = [\"food was tasty\",\"I enjoy having you here\"]\n",
    "\n",
    "NonTypes = ['PRP','PRP$','TO','WP','WP$','IN','DT']\n",
    "\n",
    "for usrtxt in sentences:\n",
    "    #usrtxt = Clean(usrtxt) #.split(\" \")\n",
    "    usrtxt = usrtxt.translate(string.maketrans(\"\",\"\"), string.punctuation) #edit\n",
    "    print \"Usr txt:\",usrtxt\n",
    "    usrtxt = word_tokenize(usrtxt)\n",
    "    usrtxt = nltk.pos_tag(usrtxt)\n",
    "\n",
    "    emojis = []\n",
    "\n",
    "    for w in usrtxt:\n",
    "        #print w\n",
    "        \n",
    "        #Check if word is really valid\n",
    "        if w[1] in NonTypes:\n",
    "            emojis.append(w[0])\n",
    "            continue\n",
    "        else:\n",
    "            w = w[0]\n",
    "            \n",
    "        #get definition of the word in our given sentence\n",
    "        try:\n",
    "            dfn = dictionary.meaning(w)\n",
    "            if dfn==None:\n",
    "                print \"Could not find definition for:\",w\n",
    "                print dfn\n",
    "                emojis.append(w)\n",
    "                continue\n",
    "        except:\n",
    "            print \"Could not find definition for:\",w\n",
    "            continue\n",
    "        #given definition for word 'w' in list dfn_words\n",
    "        dfn_words = []\n",
    "        for key in dfn:\n",
    "            words = dfn[key]\n",
    "            words = \" \".join(words)\n",
    "            words = Clean(words).split(\" \")\n",
    "            dfn_words = dfn_words + words\n",
    "        \n",
    "        #print dfn_words\n",
    "        \n",
    "        #Define a list of similarity values\n",
    "        similarity = []\n",
    "\n",
    "        #compare every definition word to every description definition word \n",
    "        #print \"getting similarities...\"\n",
    "        \n",
    "    # [X] GET SIMILARITY BASED ON AVERAGE SIMILARITY BETWEEN ALL WORD DEFINITIONS AND EMOJI DEFINITIONS\n",
    "        #similarity = emoji_key.DescDef.apply(lambda x: compare(x.split(\" \"), dfn_words) )\n",
    "    \n",
    "    #GET SIMILARITY BASED ON VECTOR SUM OF SIMILARITY BETWEEN SUM(WORD DEFINITIONS) AND SUM(EMOJI DEFINITIONS)\n",
    "        similarity = emoji_key.DescDef.apply(lambda x: compare_alt(x.split(\" \"), dfn_words) )\n",
    "    \n",
    "    #GET SIMILARITY BASED ON VECTOR SUM OF SIMILARITY BETWEEN WORD AND EMOJI DESCRIPTION\n",
    "        similarity += emoji_key.Description.apply(lambda x: compare_alt(x.split(\" \"), [w]) )\n",
    "    \n",
    "    #GET SIMILARITY BASED ON BETWEEN WORD AND EMOJI DESCRIPTION (vector average and take euclidian distance)\n",
    "        similarity += emoji_key.Description.apply(lambda x: compare_alt1(x.split(\" \"), [w], avg=True) )\n",
    "    \n",
    "    #GET SIMILARITY BASED ON AVERAGE SIMILARITY BETWEEN WORD AND EMOJI DESCRIPTION SYNONYM WORDS\n",
    "        similarity += emoji_key.Synonyms.apply(lambda x: compare(x.split(\" \"), [w]) )\n",
    "    \n",
    "    #GET SIMILARITY BASED ON SIMILARITY BETWEEN WORD AND EMOJI DESC. SYNONYM WORDS (vector average and take euclidian distance)\n",
    "        similarity += emoji_key.Synonyms.apply(lambda x: compare_alt1(x.split(\" \"), [w], avg=True) )\n",
    "    \n",
    "    #GET SIMILARITY BASED ON SIMILARITY BETWEEN WORD SYNONYMS AND EMOJI DESC. SYNONYMS (vector average and take euclidian distance)\n",
    "        #w_syns = [w]+dictionary.synonym(w)[:2]\n",
    "        #similarity = emoji_key.Synonyms.apply(lambda x: compare_alt1(x.split(\" \"), w_syns, avg=True) )\n",
    "    \n",
    "    #GET SIMILARITY BASED ON SIMILARITY BETWEEN ALL WORD DEFS AND EMOJI DEFS (vector sum and take euclidian distance)\n",
    "        #similarity = emoji_key.DescDef.apply(lambda x: compare_alt1(x.split(\" \"), dfn_words, avg=False) )\n",
    "        \n",
    "        tops = sorted(zip(similarity, range(len(similarity))), reverse=True)[:3]\n",
    "        #print tops\n",
    "        print w+\":\"\n",
    "        for x in tops:\n",
    "            print emoji_key.Native.values[x[1]],\\\n",
    "            emoji_key.Description.values[x[1]],\\\n",
    "            similarity[x[1]]\n",
    "\n",
    "        emojis.append(emoji_key.Native.values[tops[0][1]])\n",
    "\n",
    "    for i in emojis:\n",
    "        print i\n",
    "    print \"\\n\"\n",
    "#     if max(match)>0.5:\n",
    "#         print emoji_key.Native.values[match.index(max(match))],\\\n",
    "#         emoji_key.Description.values[match.index(max(match))],\\\n",
    "#         max(match)\n",
    "#     else:\n",
    "#         print \"no match >0.8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('take', 'VBP'), ('what', 'WP'), ('like', 'IN'), ('If', 'IN'), ('you', 'PRP'), ('love', 'VBP'), ('to', 'TO'), ('do', 'VB'), ('this', 'DT'), ('love', 'VB')]\n",
      "PRP\n"
     ]
    }
   ],
   "source": [
    "text = word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
    "text = word_tokenize(\"I like to eat chicken like cows do\")\n",
    "text = word_tokenize(\"I take what like If you love to do this love\")\n",
    "tags = nltk.pos_tag(text)\n",
    "print tags\n",
    "print tags[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
